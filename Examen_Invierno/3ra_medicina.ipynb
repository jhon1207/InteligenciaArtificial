{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Apellidos y Nombre: Zuñiga Mendez Jhonny Agustin\n",
    "Carrera:Ingieneria de Sistemas\n",
    "GitHub:\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Elaborar un cuadernillo que permita demostrar la utilidad de la clasificación multiclase en el ámbito de la clasificación \n",
    "aplicada a la medicina. El código fuente del cuadernillo puede ser original o apropiado de un tercero, el código fuente \n",
    "no debe utilizar librerías o servicios de terceros, si se copia código se debe referenciar al autor. Se debe comentar \n",
    "todo el código fuente de la manera que considere apropiada el estudiante, a fin de dar la claridad suficiente en la \n",
    "explicación.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase Nodo del Árbol de Decisión\n",
    "class NodoDecision:\n",
    "    def __init__(self, indice_caracteristica=None, umbral=None, valor=None, rama_verdadera=None, rama_falsa=None):\n",
    "        self.indice_caracteristica = indice_caracteristica  # Índice de la característica a dividir\n",
    "        self.umbral = umbral  # Valor de corte para la característica\n",
    "        self.valor = valor  # Etiqueta de la clase (solo para nodos hoja)\n",
    "        self.rama_verdadera = rama_verdadera  # Subárbol verdadero\n",
    "        self.rama_falsa = rama_falsa  # Subárbol falso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la impureza de Gini\n",
    "def impureza_gini(etiquetas):\n",
    "    total_muestras = len(etiquetas)\n",
    "    conteo_clases = {} #diccionario que se inicializa en vacio, se utiliza para almacenar el conteo de cada etiqueta\n",
    "    for etiqueta in etiquetas:\n",
    "        conteo_clases[etiqueta] = conteo_clases.get(etiqueta, 0) + 1 #devuelve el valor asociado a una clave especifica\n",
    "                                                                     #si esta presente en el diccionario\n",
    "    impureza = 1\n",
    "    for conteo in conteo_clases.values():\n",
    "        probabilidad_clase = conteo / total_muestras #calcula la probabilidad de la clase \n",
    "        impureza -= probabilidad_clase ** 2 #acumula las impuresas a medida que recorren todas las clases en el conjunto \n",
    "                                            #de datos\n",
    "    return impureza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para dividir los datos en dos ramas basadas en la característica y el valor de corte\n",
    "# donde X es una lista de listas que contiene un conjunto de datos\n",
    "# y Es una lista que contiene las etiquetas de clase correspondientes a cada muestra en el conjunto de datos X.\n",
    "# umbral Valor de corte para la característica\n",
    "#indice Es un entero que representa el índice de la característica que se utilizará para realizar la división.\n",
    "def dividir_datos(X, y, indice_caracteristica, umbral):\n",
    "    X_izquierda, y_izquierda, X_derecha, y_derecha = [], [], [], []\n",
    "    for i in range(len(X)):#recorre cada muestra en el conjunto de datos X generando las etiquetas correspondientes\n",
    "        if X[i][indice_caracteristica] <= umbral:\n",
    "            X_izquierda.append(X[i])\n",
    "            y_izquierda.append(y[i])\n",
    "        else:\n",
    "            X_derecha.append(X[i]) #etiquetas correspondientes\n",
    "            y_derecha.append(y[i]) #subconjunto para construir las ramas verdaderas o falsa \n",
    "    return X_izquierda, y_izquierda, X_derecha, y_derecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para encontrar la mejor división que minimiza la impureza de Gini\n",
    "def encontrar_mejor_division(X, y):\n",
    "    mejor_gini = 1\n",
    "    mejor_criterio = None  # Almacena el mejor criterio de división\n",
    "    n_caracteristicas = len(X[0])#numero total de caracteristicas o columnas \n",
    "\n",
    "    for indice_caracteristica in range(n_caracteristicas):#recorre cada indice de caracteristica de 0 a n_caracteristicas -1\n",
    "        valores_unicos = set(x[indice_caracteristica] for x in X)#Se obtienen los valores únicos para la característica actual\n",
    "        for umbral in valores_unicos:#recorre cada umbral presente en los valores únicos para la característica actual\n",
    "            X_izquierda, y_izquierda, X_derecha, y_derecha = dividir_datos(X, y, indice_caracteristica, umbral)\n",
    "            #Se divide el conjunto de datos X y sus etiquetas y en dos subconjuntos\n",
    "            gini_izquierda = impureza_gini(y_izquierda)#Se calcula la impureza de Gini para el subconjunto izquierdo\n",
    "            gini_derecha = impureza_gini(y_derecha)#Se calcula la impureza de Gini para el subconjunto derecho\n",
    "\n",
    "            # Calcula la impureza de Gini para la división\n",
    "            gini = (len(y_izquierda) / len(y)) * gini_izquierda + (len(y_derecha) / len(y)) * gini_derecha\n",
    "\n",
    "            # Actualiza el mejor criterio de división si es necesario\n",
    "            if gini < mejor_gini:\n",
    "                mejor_gini = gini\n",
    "                mejor_criterio = (indice_caracteristica, umbral)\n",
    "\n",
    "    return mejor_gini, mejor_criterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para construir el árbol de decisión recursivamente\n",
    "def construir_arbol(X, y, profundidad=0, profundidad_maxima=None):\n",
    "    if profundidad == profundidad_maxima or len(set(y)) == 1:\n",
    "        # Crear un nodo hoja si se alcanza la profundidad máxima o todas las etiquetas son iguales\n",
    "        return NodoDecision(valor=max(set(y), key=y.count))\n",
    "\n",
    "    mejor_gini, mejor_criterio = encontrar_mejor_division(X, y)#encuentra la mejor division que minimiza la impureza de gini\n",
    "    indice_caracteristica, umbral = mejor_criterio #Se extraen el índice de característica y el umbral óptimos \n",
    "    #divide el conjunto de datos en 2 subconjuntos con sus etiquetas correspondientes\n",
    "    X_izquierda, y_izquierda, X_derecha, y_derecha = dividir_datos(X, y, indice_caracteristica, umbral)\n",
    "    #llamada recursiva a la función construir_arbol para construir la rama verdadera del árbol utilizando el subconjunto izquierdo \n",
    "    rama_verdadera = construir_arbol(X_izquierda, y_izquierda, profundidad + 1, profundidad_maxima)\n",
    "    #llamada recursiva a la función construir_arbol para construir la rama falsa del árbol utilizando el subconjunto derecho\n",
    "    rama_falsa = construir_arbol(X_derecha, y_derecha, profundidad + 1, profundidad_maxima)\n",
    "\n",
    "    return NodoDecision(indice_caracteristica=indice_caracteristica, umbral=umbral, rama_verdadera=rama_verdadera,\n",
    "                        rama_falsa=rama_falsa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase predicha: Dudoso\n"
     ]
    }
   ],
   "source": [
    "# Función para hacer predicciones utilizando el árbol de decisión y obtener el resultado en texto\n",
    "def predecir_arbol_en_texto(muestra, arbol):\n",
    "    if arbol.valor is not None:#comprueba si el nodo actual del árbol (arbol) es un nodo hoja\n",
    "        #si no es none significa que el nodo es un nodo hoja y contiene una etiqueta de clase (resultado) en forma numérica.\n",
    "        return etiquetas_clase_a_resultados[arbol.valor]\n",
    "    #Si el valor de la característica es menor o igual al umbral, se sigue la rama verdadera del árbol realizando la llamada recursiva\n",
    "    if muestra[arbol.indice_caracteristica] <= arbol.umbral:\n",
    "        return predecir_arbol_en_texto(muestra, arbol.rama_verdadera)\n",
    "    else:\n",
    "        return predecir_arbol_en_texto(muestra, arbol.rama_falsa)\n",
    "etiquetas_clase_a_resultados = {\n",
    "    0: \"Negativo\",\n",
    "    1: \"Positivo\",\n",
    "    2: \"Dudoso\"\n",
    "}\n",
    "\n",
    "# Conjunto de datos de entrenamiento ficticio con más características\n",
    "X_entrenamiento = [[37.2, 1, 1, 1, 1],\n",
    "                   [36.5, 0, 0, 1, 0],\n",
    "                   [38.0, 1, 0, 0, 1],\n",
    "                   [36.8, 0, 1, 0, 0],\n",
    "                   [37.4, 1, 1, 1, 0],\n",
    "                   [37.9, 0, 0, 0, 1],\n",
    "                   [38.2, 1, 1, 1, 0],\n",
    "                   [36.9, 0, 1, 1, 0]]\n",
    "\n",
    "y_entrenamiento = [1, 0, 2, 0, 1, 0, 2, 0]\n",
    "\n",
    "# Entrenar el modelo (Árbol de Decisión)\n",
    "arbol_entrenado = construir_arbol(X_entrenamiento, y_entrenamiento, profundidad_maxima=7)\n",
    "\n",
    "# Datos para predecir con más características\n",
    "X_nuevos = [[38.7, 1, 1, 1, 1]]\n",
    "\n",
    "# Realizar predicciones\n",
    "clase_predicha = predecir_arbol_en_texto(X_nuevos[0], arbol_entrenado)\n",
    "\n",
    "# Imprimir la clase predicha en texto\n",
    "print(\"Clase predicha:\", clase_predicha)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
